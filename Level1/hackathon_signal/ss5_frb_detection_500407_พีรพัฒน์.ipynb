{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 91438,
          "databundleVersionId": 11038850,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30887,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#original train code\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm.notebook import tqdm\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "data_train_dir = '/kaggle/input/signal-fast-radio-burst-detection/train/train'\n",
        "data_labels_dir = '/kaggle/input/signal-fast-radio-burst-detection/train-labels-corrected/train'\n",
        "\n",
        "def load_large_npy(file_path):\n",
        "    return np.memmap(file_path, dtype=np.float32, mode='r')\n",
        "\n",
        "label_mapping = {\n",
        "    \"None\": [0, 0, 0],\n",
        "    \"Pulse\": [1, 0, 0],\n",
        "    \"Broad\": [0, 1, 0],\n",
        "    \"Narrow\": [0, 0, 1],\n",
        "    \"Broad+Pulse\": [1, 1, 0],\n",
        "    \"Narrow+Pulse\": [1, 0, 1],\n",
        "    \"Narrow+Broad\": [0, 1, 1],\n",
        "    \"Pulse+Broad+Narrow\": [1, 1, 1]\n",
        "}\n",
        "\n",
        "signals = []\n",
        "labels = []\n",
        "\n",
        "for filename in tqdm(os.listdir(data_labels_dir)[0:10] + os.listdir(data_labels_dir)[35:70]):\n",
        "    filename_noext = filename[:-11]\n",
        "\n",
        "    labels_csv = pd.read_csv(os.path.join(data_labels_dir, filename))\n",
        "\n",
        "    # data_signals = load_large_npy(os.path.join(data_train_dir, f'{filename_noext}.npy'))\n",
        "\n",
        "    data_signals = np.load(os.path.join(data_train_dir, f'{filename_noext}.npy'))\n",
        "\n",
        "    chunk_size = 256\n",
        "    num_chunks = len(data_signals) // chunk_size\n",
        "    index_label = 0\n",
        "\n",
        "    for i in range(num_chunks):\n",
        "        start_ = i * chunk_size\n",
        "        end_ = start_ + chunk_size\n",
        "        chunk_signal = data_signals[start_:end_].astype(np.float32)\n",
        "\n",
        "        label_row = labels_csv[labels_csv['index'] == index_label]\n",
        "\n",
        "        label_ = label_row['labels'].values[0]\n",
        "\n",
        "        if pd.isna(label_):\n",
        "            label_ = \"None\"\n",
        "\n",
        "        # print(label_)\n",
        "\n",
        "        if label_ not in label_mapping:\n",
        "            index_label += 1\n",
        "            continue\n",
        "        # print('processed: ' ,label_mapping[label_])\n",
        "        # print(chunk_signal.shape)\n",
        "        signals.append(chunk_signal)\n",
        "        labels.append(label_mapping[label_])\n",
        "\n",
        "        index_label += 1\n",
        "\n",
        "class SignalDataset(Dataset):\n",
        "    def __init__(self, signals, labels):\n",
        "        self.signals = torch.tensor(np.array(signals), dtype=torch.float32)\n",
        "        self.labels = torch.tensor(np.array(labels), dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.signals)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # เพิ่มมิติ channel ให้เป็น (1, 256, 256) สำหรับ Conv2D\n",
        "        signal = self.signals[idx].unsqueeze(0)\n",
        "        label = self.labels[idx]\n",
        "        return signal, label\n",
        "\n",
        "\n",
        "dataset = SignalDataset(signals, labels)\n",
        "signal, label = dataset[0]\n",
        "# คำนวณ class weights จาก labels\n",
        "labels_tensor = torch.tensor(labels)  # แปลงเป็น Tensor\n",
        "class_indices = torch.argmax(labels_tensor, dim=1)  # แปลง one-hot → class index\n",
        "class_counts = torch.bincount(class_indices)  # นับจำนวนแต่ละ class\n",
        "class_weights = 1.0 / class_counts.float()  # คำนวณ weight ของแต่ละ class\n",
        "sample_weights = class_weights[class_indices]  # กำหนด weight ให้แต่ละ sample\n",
        "\n",
        "# สร้าง WeightedRandomSampler\n",
        "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "\n",
        "# ใช้กับ DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=8, sampler=sampler ,pin_memory=True)\n",
        "\n",
        "# ทดสอบว่ามันสุ่มอะไรออกมา\n",
        "for i, (signal, label) in enumerate(dataloader):\n",
        "    print(f\"Batch {i}: Signal Shape: {signal.shape}, Label: {label.numpy()}\")\n",
        "    if i == 2:  # แสดงแค่ 3 batch\n",
        "        break\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-08T22:04:25.157506Z",
          "iopub.execute_input": "2025-02-08T22:04:25.157825Z",
          "iopub.status.idle": "2025-02-08T22:06:03.241354Z",
          "shell.execute_reply.started": "2025-02-08T22:04:25.157799Z",
          "shell.execute_reply": "2025-02-08T22:06:03.240194Z"
        },
        "colab": {
          "referenced_widgets": [
            "5215925e312044a9ac419ec5e3afb52c"
          ]
        },
        "id": "aN2dsYtOVOe8",
        "outputId": "bc9b87bf-991b-4f79-adaf-16ac179bfa1d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/45 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5215925e312044a9ac419ec5e3afb52c"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Batch 0: Signal Shape: torch.Size([8, 1, 256, 256]), Label: [[0. 0. 1.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 0. 0.]\n [0. 0. 1.]]\nBatch 1: Signal Shape: torch.Size([8, 1, 256, 256]), Label: [[0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 0.]\n [0. 1. 0.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 1. 0.]\n [0. 1. 0.]]\nBatch 2: Signal Shape: torch.Size([8, 1, 256, 256]), Label: [[0. 1. 0.]\n [0. 1. 0.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 0.]\n [0. 1. 0.]\n [0. 1. 0.]]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-08T22:06:03.242554Z",
          "iopub.execute_input": "2025-02-08T22:06:03.242827Z",
          "iopub.status.idle": "2025-02-08T22:06:03.248498Z",
          "shell.execute_reply.started": "2025-02-08T22:06:03.242803Z",
          "shell.execute_reply": "2025-02-08T22:06:03.247571Z"
        },
        "id": "MYqn_6qBVOfA",
        "outputId": "0e367560-8939-4b14-9ac0-2b4a620b0f39"
      },
      "outputs": [
        {
          "execution_count": 2,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<torch.utils.data.dataloader.DataLoader at 0x7ac0eda47dc0>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# normal CNN\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "# สร้างโมเดล CNN\n",
        "class SignalCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SignalCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(64 * 32 * 32, 128)  # Flatten ข้อมูล\n",
        "        self.fc2 = nn.Linear(128, 3)  # 3 class output (ใช้ softmax ภายหลัง)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)  # (B, 16, 128, 128)\n",
        "\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)  # (B, 32, 64, 64)\n",
        "\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.max_pool2d(x, 2)  # (B, 64, 32, 32)\n",
        "\n",
        "        x = torch.flatten(x, start_dim=1)  # Flatten\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)  # ไม่มี softmax เพราะใช้ CrossEntropyLoss\n",
        "        return x\n",
        "\n",
        "# กำหนด Loss Function และ Optimizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SignalCNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# เทรนโมเดล\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for signals, labels in tqdm(dataloader):\n",
        "        signals, labels = signals.to(device), labels.to(device)\n",
        "\n",
        "        # เปลี่ยน labels จาก One-Hot → Class Index\n",
        "        labels = torch.argmax(labels, dim=1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(signals)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(dataloader):.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-08T22:02:43.103824Z",
          "iopub.status.idle": "2025-02-08T22:02:43.104212Z",
          "shell.execute_reply": "2025-02-08T22:02:43.104033Z"
        },
        "jupyter": {
          "source_hidden": true
        },
        "id": "MmUtV6akVOfB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Load ResNet-50 model and modify it for your task\n",
        "class ResNet50Modified(nn.Module):\n",
        "    def __init__(self, num_classes=3):\n",
        "        super(ResNet50Modified, self).__init__()\n",
        "\n",
        "        # Load pre-trained ResNet-50\n",
        "        self.resnet50 = models.resnet50(pretrained=True)\n",
        "\n",
        "        # Modify the first convolution layer to accept 1 channel instead of 3\n",
        "        self.resnet50.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "\n",
        "        # Modify the fully connected layer to match the number of classes\n",
        "        self.resnet50.fc = nn.Linear(self.resnet50.fc.in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet50(x)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Create the model\n",
        "model = ResNet50Modified(num_classes=3).to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 5\n",
        "\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for signals, labels in tqdm(dataloader):\n",
        "        signals, labels = signals.to(device), labels.to(device)\n",
        "\n",
        "        # Convert one-hot labels to class indices\n",
        "        labels = torch.argmax(labels, dim=1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(signals)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()fl\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(dataloader):.4f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-08T22:06:05.452174Z",
          "iopub.execute_input": "2025-02-08T22:06:05.452568Z",
          "iopub.status.idle": "2025-02-08T22:44:54.808728Z",
          "shell.execute_reply.started": "2025-02-08T22:06:05.452533Z",
          "shell.execute_reply": "2025-02-08T22:44:54.807502Z"
        },
        "colab": {
          "referenced_widgets": [
            "f933fe83851d425ea39649f0662fbe7c",
            "a70c5a52d27a4589a1ccbb3d8f3fe650",
            "eb821ee9c3604332969acb8eddbe7013",
            "05660cc911244f7ab5aab003ef9b2102",
            "d752351db78e4c0f9fbb5aabdc9f95a1",
            "f0c053ab8bc8469c8950965a593d540d"
          ]
        },
        "id": "SvStLsqyVOfB",
        "outputId": "94a827ba-ef4f-40f0-b232-269cd1be1c34"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/5 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f933fe83851d425ea39649f0662fbe7c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/4161 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a70c5a52d27a4589a1ccbb3d8f3fe650"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch [1/5], Loss: 0.4227\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/4161 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb821ee9c3604332969acb8eddbe7013"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch [2/5], Loss: 0.1746\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/4161 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05660cc911244f7ab5aab003ef9b2102"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch [3/5], Loss: 0.1341\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/4161 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d752351db78e4c0f9fbb5aabdc9f95a1"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch [4/5], Loss: 0.1111\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/4161 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f0c053ab8bc8469c8950965a593d540d"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch [5/5], Loss: 0.0856\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# เซฟโมเดลที่เรียนรู้แล้ว\n",
        "torch.save(model.state_dict(), \"signal_cnn.pth\")\n",
        "print(\"Model saved as signal_cnn.pth ✅\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-08T22:44:59.795884Z",
          "iopub.execute_input": "2025-02-08T22:44:59.796447Z",
          "iopub.status.idle": "2025-02-08T22:44:59.952352Z",
          "shell.execute_reply.started": "2025-02-08T22:44:59.796416Z",
          "shell.execute_reply": "2025-02-08T22:44:59.951318Z"
        },
        "id": "Qykd8S2aVOfC",
        "outputId": "365f85b4-8108-45f7-ecd7-5c9a328057a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Model saved as signal_cnn.pth ✅\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    sample_signal = np.load('/kaggle/input/signal-fast-radio-burst-detection/train/train/B0531+21_2020-05-31-11_36_46_0001023.npy')[:256]\n",
        "\n",
        "    # แปลงเป็น Tensor และย้ายไป GPU\n",
        "    sample_signal = torch.tensor(sample_signal, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
        "\n",
        "    # ส่งเข้าโมเดล\n",
        "    model = model.to(device)  # ย้ายโมเดลไป GPU\n",
        "    output = model(sample_signal)\n",
        "    print(output)\n",
        "\n",
        "    predicted_class = torch.argmax(output, dim=1).item()\n",
        "    print(f\"Predicted Class: {predicted_class}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-08T22:02:43.107170Z",
          "iopub.status.idle": "2025-02-08T22:02:43.107574Z",
          "shell.execute_reply": "2025-02-08T22:02:43.107381Z"
        },
        "id": "o9iGUmIeVOfC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm.notebook import tqdm  # Ensure you have tqdm imported for the progress bars\n",
        "\n",
        "# Assuming the model and device have been set up already\n",
        "class_labels = [\"Pulse\", \"Broad\", \"Narrow\"]\n",
        "test_dir = '/kaggle/input/signal-fast-radio-burst-detection/test/test'\n",
        "\n",
        "# Initialize an empty dictionary to store predictions\n",
        "predictions_dict = {}\n",
        "\n",
        "# Loop through files in the directory\n",
        "for filename in tqdm(os.listdir(test_dir)):\n",
        "    if filename.endswith('.npy'):  # Only process .npy files\n",
        "        file_path = os.path.join(test_dir, filename)\n",
        "\n",
        "        # Load the signal data\n",
        "        data_signals = np.load(file_path)\n",
        "\n",
        "        # Process the file in chunks of 256\n",
        "        chunk_size = 256\n",
        "        num_chunks = len(data_signals) // chunk_size\n",
        "\n",
        "        # Pad data if necessary\n",
        "        if num_chunks * chunk_size != len(data_signals):\n",
        "            pad_length = chunk_size - (len(data_signals) % chunk_size)\n",
        "            data_signals = np.pad(data_signals, ((0, pad_length), (0, 0)), mode='constant', constant_values=0)\n",
        "            num_chunks = len(data_signals) // chunk_size\n",
        "\n",
        "        # Loop through each chunk and predict\n",
        "        for i in tqdm(range(num_chunks)):\n",
        "            start_idx = i * chunk_size\n",
        "            end_idx = start_idx + chunk_size\n",
        "            chunk_signal = data_signals[start_idx:end_idx]\n",
        "\n",
        "            # Reshape for the model input\n",
        "            signals_tensor = torch.tensor(chunk_signal, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)  # Shape (1, 1, 256, 256)\n",
        "\n",
        "            # Predict using the model\n",
        "            with torch.no_grad():\n",
        "                outputs = model(signals_tensor)\n",
        "\n",
        "            # Convert logits to probabilities using sigmoid\n",
        "            probabilities = torch.sigmoid(outputs)  # Use sigmoid for multi-label classification\n",
        "\n",
        "            # Apply threshold of 0.5 to classify each label\n",
        "            predicted_labels = (probabilities > 0.5).int()  # Binary classification for each class\n",
        "\n",
        "            # Create an entry for the chunk in the dictionary\n",
        "            chunk_key = f\"{filename[:-4]}_{i}\"  # Use the filename (without extension) and chunk number as key\n",
        "            predictions_dict[chunk_key] = {\n",
        "                \"pulse\": predicted_labels[0, 0].item(),\n",
        "                \"broad\": predicted_labels[0, 1].item(),\n",
        "                \"narrow\": predicted_labels[0, 2].item()\n",
        "            }\n",
        "\n",
        "# Convert the dictionary to a DataFrame\n",
        "df = pd.DataFrame.from_dict(predictions_dict, orient='index')\n",
        "\n",
        "# Add 'id' column with the 'index' value\n",
        "df['id'] = df.index\n",
        "\n",
        "# Reorder columns so that 'id' comes first\n",
        "df = df[['id', 'pulse', 'broad', 'narrow']]\n",
        "\n",
        "# Reset the index for a clean structure\n",
        "df = df.reset_index(drop=True)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-08T23:06:57.962222Z",
          "iopub.execute_input": "2025-02-08T23:06:57.962617Z",
          "iopub.status.idle": "2025-02-08T23:11:18.197410Z",
          "shell.execute_reply.started": "2025-02-08T23:06:57.962584Z",
          "shell.execute_reply": "2025-02-08T23:11:18.196563Z"
        },
        "colab": {
          "referenced_widgets": [
            "bfd6b067383c4ca4ba00cd5659f1f428",
            "67891d4386bd44c4afe0f19ac6354dad",
            "61662658d2bc4296a078010d8af829b6",
            "326bc2ee6d8d4bc69bb4bd2589cab34e",
            "d30e450fa46044368692e0f17474cb6c",
            "cb5188f9064c44fc92a659675d93cdfc",
            "e1cd020d57e842809587e537569a345e",
            "3eee995c2fb34b6b864dffc3317e66c5",
            "56732365140146cdbd72c904a4670e19",
            "5bfe1f599e7b4a58876ccccdbbe22b93",
            "37f539642e0140c4b58b772bf818ee82",
            "7a642823b46541fdae96091c383eaebc",
            "d7003566eb4844799df24f55e2c557a6",
            "0e65aca353e34d68b9fa9ce71bf021c6",
            "2d8e9ca99a8d4c828f7fc1a72c5c55bd",
            "1808ea4f983f4822a73995e936d4a457",
            "564d32d8f51d4d51a66081d4e4358acc",
            "61e2262fa3a94244ae4679425a9d208d",
            "ab8a09d6f99e457b8a1dcb5a19579a99",
            "18059585211a4d9686d57180c3971006",
            "bd89d6ae413a466380dba585bc78462f",
            "8027b2d493f4422689ce835019fd5a6d",
            "26a22abfead34b3eae58331c334573cb",
            "b15f8802cd694949851f18b22295eca3",
            "3aed6b7d1e274b4e82a837b03e1de17e",
            "35450d5620274f148cdcf21c7b0b15be",
            "323f00c7ae474e099fbb3db7143ad9af",
            "344538c6b457481696cc194f2ff0d157",
            "6167f6c2393449249556e937ebafed7f",
            "b919832431d448bb9d742c877b7f8944",
            "b725bf42527a45e2b2ab5cb15fcc7784",
            "27247327540b4dd39314d75eea2da88c",
            "aa76c901713040668db7284cccb5a45c",
            "4e9658d229954a14b8dda8678b7385ac"
          ]
        },
        "id": "TYD4KRaaVOfD",
        "outputId": "7bb31c03-1f08-4262-814c-b3aeafea102e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/33 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bfd6b067383c4ca4ba00cd5659f1f428"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/1024 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67891d4386bd44c4afe0f19ac6354dad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/1024 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61662658d2bc4296a078010d8af829b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/1024 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "326bc2ee6d8d4bc69bb4bd2589cab34e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/1024 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d30e450fa46044368692e0f17474cb6c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/1024 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cb5188f9064c44fc92a659675d93cdfc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/132 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e1cd020d57e842809587e537569a345e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/68 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3eee995c2fb34b6b864dffc3317e66c5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/1024 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "56732365140146cdbd72c904a4670e19"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/500 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5bfe1f599e7b4a58876ccccdbbe22b93"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/1024 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37f539642e0140c4b58b772bf818ee82"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/1024 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a642823b46541fdae96091c383eaebc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/1024 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d7003566eb4844799df24f55e2c557a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/452 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e65aca353e34d68b9fa9ce71bf021c6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/503 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d8e9ca99a8d4c828f7fc1a72c5c55bd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/500 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1808ea4f983f4822a73995e936d4a457"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/1024 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "564d32d8f51d4d51a66081d4e4358acc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/1024 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61e2262fa3a94244ae4679425a9d208d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/1024 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab8a09d6f99e457b8a1dcb5a19579a99"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/498 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "18059585211a4d9686d57180c3971006"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/1024 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bd89d6ae413a466380dba585bc78462f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/1024 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8027b2d493f4422689ce835019fd5a6d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/1024 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "26a22abfead34b3eae58331c334573cb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/403 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b15f8802cd694949851f18b22295eca3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/1024 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3aed6b7d1e274b4e82a837b03e1de17e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/999 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35450d5620274f148cdcf21c7b0b15be"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/1024 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "323f00c7ae474e099fbb3db7143ad9af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/1024 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "344538c6b457481696cc194f2ff0d157"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/1024 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6167f6c2393449249556e937ebafed7f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/1024 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b919832431d448bb9d742c877b7f8944"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/501 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b725bf42527a45e2b2ab5cb15fcc7784"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/1024 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "27247327540b4dd39314d75eea2da88c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/1024 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa76c901713040668db7284cccb5a45c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/1024 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4e9658d229954a14b8dda8678b7385ac"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "            id  pulse  broad  narrow\n0         23_0      1      0       0\n1         23_1      1      0       0\n2         23_2      1      0       0\n3         23_3      0      0       0\n4         23_4      1      0       0\n...        ...    ...    ...     ...\n28103  16_1019      1      0       0\n28104  16_1020      1      0       0\n28105  16_1021      1      0       0\n28106  16_1022      1      0       0\n28107  16_1023      1      0       0\n\n[28108 rows x 4 columns]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df['numeric_id'] = df['id'].str.split('_').str[0].astype(int)\n",
        "df['chunk_id'] = df['id'].str.split('_').str[1].astype(int)\n",
        "\n",
        "# Sort by numeric part and then by chunk number\n",
        "df_sorted = df.sort_values(by=['numeric_id', 'chunk_id'])\n",
        "\n",
        "# Reorder columns so that 'id' is first\n",
        "df_sorted = df_sorted[['id', 'pulse', 'broad', 'narrow']]\n",
        "\n",
        "# Reset the index for a clean structure\n",
        "df_sorted = df_sorted.reset_index(drop=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-08T23:12:29.203668Z",
          "iopub.execute_input": "2025-02-08T23:12:29.204039Z",
          "iopub.status.idle": "2025-02-08T23:12:29.266520Z",
          "shell.execute_reply.started": "2025-02-08T23:12:29.204009Z",
          "shell.execute_reply": "2025-02-08T23:12:29.265533Z"
        },
        "id": "jeYAQn2DVOfD"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df_sorted"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-08T23:12:35.646756Z",
          "iopub.execute_input": "2025-02-08T23:12:35.647071Z",
          "iopub.status.idle": "2025-02-08T23:12:35.657083Z",
          "shell.execute_reply.started": "2025-02-08T23:12:35.647048Z",
          "shell.execute_reply": "2025-02-08T23:12:35.656132Z"
        },
        "id": "A8tf0IjqVOfE",
        "outputId": "6a9a32e1-4161-4f03-e98a-35cca1b214a3"
      },
      "outputs": [
        {
          "execution_count": 28,
          "output_type": "execute_result",
          "data": {
            "text/plain": "           id  pulse  broad  narrow\n0         0_0      1      0       0\n1         0_1      1      0       0\n2         0_2      1      0       0\n3         0_3      1      0       0\n4         0_4      1      0       0\n...       ...    ...    ...     ...\n28103  32_398      1      0       0\n28104  32_399      1      0       0\n28105  32_400      1      0       0\n28106  32_401      1      0       0\n28107  32_402      1      0       0\n\n[28108 rows x 4 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>pulse</th>\n      <th>broad</th>\n      <th>narrow</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0_0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0_1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0_2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0_3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0_4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>28103</th>\n      <td>32_398</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>28104</th>\n      <td>32_399</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>28105</th>\n      <td>32_400</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>28106</th>\n      <td>32_401</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>28107</th>\n      <td>32_402</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>28108 rows × 4 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the sorted DataFrame to a CSV file\n",
        "df_sorted.to_csv('/kaggle/working/sorted_predictions.csv', index=False)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-08T23:13:11.334636Z",
          "iopub.execute_input": "2025-02-08T23:13:11.334950Z",
          "iopub.status.idle": "2025-02-08T23:13:11.371246Z",
          "shell.execute_reply.started": "2025-02-08T23:13:11.334928Z",
          "shell.execute_reply": "2025-02-08T23:13:11.370556Z"
        },
        "id": "3qOKhydPVOfE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "djwXf4IkVOfI"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}